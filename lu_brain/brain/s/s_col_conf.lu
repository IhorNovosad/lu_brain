/**
	Copyright Â© 2020 Oleh Ihorovych Novosad 
*/

///////////////////////////////////////////////////////////////////////////////
// 

	static S_Col_Conf s_col_conf_init(S_Col_Conf self, Mem mem, lu_size component_size, lu_value min, lu_value max, lu_size neu_size, lu_size nsc)
	{
		self->component_size 	= component_size;
		self->neu_size  		= neu_size; // value depth in indexes
		self->orig_min 			= min;
		self->orig_max 			= max;
		self->max 				= self->orig_max - self->orig_min;
		self->step 				= self->max / (lu_value) self->neu_size;
		self->nsc 				= nsc; //(lu_size) lu_value_round(self->max_val * rec->val_nsc / self->step); // nsc in indexes

	 	// Kroky preobchysleni
		self->steps 		= (lu_value*) mem_alloc(mem, sizeof(lu_value) * self->neu_size);
		lu_user_assert(self->steps, "Cannot allocate steps");
	
		lu_size i;
		for (i = 0; i < self->neu_size; i++)
			self->steps[i] = (lu_value)i * self->step;
	}

	static inline lu_value s_col_conf_norm(S_Col_Conf self, lu_value request)
	{
		lu_value val = request - self->orig_min;
		if (val < 0) val = 0;
		if (val > self->max) val = self->max;

		return val;
	}

	static inline lu_size s_col_conf_indx(S_Col_Conf self, lu_value val)
	{
		return (lu_size) lu_value_round(val / self->step);
	}

	static inline struct lu_size_range s_col_conf_indx_range(S_Col_Conf self, lu_value val)
	{
		lu_size orig_i = s_col_conf_indx(self, val);

		long begin, end;

		begin = orig_i - self->nsc;
		if (begin < 0) begin = 0;

		end = orig_i + self->nsc;
		if (end > (self->neu_size - 1)) end = self->neu_size - 1; 

		struct lu_size_range r;
		r.begin = (lu_size) begin;
		r.end = (lu_size) end;
		return r;
	}

	static inline lu_value s_col_conf_calc_sig(S_Col_Conf self, lu_size val_step_i, lu_value val)
	{ 
		return 1.0 - lu_value_abs(self->steps[val_step_i] - val) / self->max;
	}

	static inline lu_value s_col_conf_step_norm_dist(S_Col_Conf self)
	{
		return 1.0 / self->neu_size;
	}